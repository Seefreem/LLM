Google Photos 将黑人识别成 gorilla，也就是大猩猩。
FaceBook AI 将黑人标记为 primates 也就是灵长类动物。
Microsoft Tay 在发布16小时之后，就还是在网上发表攻击性和歧视性言论。

Meta 的Galactica 模型能进行性公式转换。但是它常常生成虚假的并且带有biased的结果。这其实是很有害的。因为如果人们相信的虚假的信息，
那么模型是不是就相当于在造谣了？如果人们根据错误的指示去做某件危险的事情，那么是不是可能会出人命？
另外，如果模型的输出是biased的，那么如果人们信了，那么是不是会加重国家或者民族之间的刻板印象，刻板印象可能会导致种族歧视，尤其是在青少年群体之间。而种族歧视可能会导致严重的暴力冲突。并且默许的偏见可能会让人们默认为某种具有伤害性的事情是正常的。这种现象时有发生。比如工作场合中的歧视，但是人们认为是正常的。但实际上并不是正常的。
另外数据层面的偏见可能是偏差。也就是不真实的数据。这也会导致问题。

所以安全的AI在某种程度上包括两个方面，第一产生的回答是真实的，如果不确定，就不要乱说。第二，产生的回答是不带偏见的，保护每一个可能的受害者。









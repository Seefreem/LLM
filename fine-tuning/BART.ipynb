{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seelur/enter/envs/pytorch_2_1_0/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/seelur/enter/envs/pytorch_2_1_0/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartModel\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large') # param 400M, file size 1G \n",
    "model = BartModel.from_pretrained('facebook/bart-large')\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "# outputs = model(**inputs)\n",
    "# last_hidden_states = outputs.last_hidden_state\n",
    "# print(last_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "dict_keys(['input_ids', 'attention_mask'])\n",
      "torch.Size([1, 8])\n",
      "torch.Size([1, 8])\n",
      "input_ids attention_mask\n"
     ]
    }
   ],
   "source": [
    "print(type(inputs))\n",
    "print(inputs.keys())\n",
    "print(inputs[\"input_ids\"].shape)\n",
    "print(inputs[\"attention_mask\"].shape)\n",
    "print(*inputs) # keays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device) # 使用GPU\n",
    "input_ids = inputs[\"input_ids\"].to(device)\n",
    "attention_mask = inputs[\"attention_mask\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside BART: Encoder: input_ids= tensor([[    0, 31414,     6,   127,  2335,    16, 11962,     2]],\n",
      "       device='cuda:0')\n",
      "Inside BART: input_ids= tensor([[    2,     0, 31414,     6,   127,  2335,    16, 11962]],\n",
      "       device='cuda:0')\n",
      "Inside BART: attention_mask= None\n",
      "Inside BART: encoder_hidden_states= tensor([[[-0.0089,  0.0095,  0.0101,  ...,  0.0054, -0.0061, -0.0019],\n",
      "         [-0.0242, -0.2558,  0.1059,  ..., -0.1760,  0.1102,  0.0296],\n",
      "         [ 0.0278, -0.2268,  0.0643,  ...,  0.0303,  0.1538, -0.1770],\n",
      "         ...,\n",
      "         [-0.0684, -0.1958, -0.0589,  ..., -0.0166,  0.1663, -0.1595],\n",
      "         [-0.0161, -0.3884, -0.4422,  ..., -0.0780,  0.0474, -0.0166],\n",
      "         [ 0.0912,  0.0469, -0.0327,  ..., -0.0290, -0.0870,  0.2132]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "Inside BART: encoder_attention_mask= tensor([[1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Inside BART: head_mask= None\n",
      "Inside BART: cross_attn_head_mask= None\n",
      "Inside BART: past_key_values= None\n",
      "Inside BART: inputs_embeds= None\n",
      "Inside BART: use_cache= True\n",
      "Inside BART: output_attentions= False\n",
      "Inside BART: output_hidden_states= False\n",
      "Inside BART: return_dict= True\n",
      "tensor([[[ 0.5512,  0.8389, -1.4707,  ...,  1.3124, -0.2047,  0.2392],\n",
      "         [ 0.5512,  0.8389, -1.4707,  ...,  1.3124, -0.2047,  0.2392],\n",
      "         [ 0.9143,  0.9399, -1.2426,  ...,  0.9184, -0.1838, -0.9975],\n",
      "         ...,\n",
      "         [ 0.2561,  0.2253,  0.4470,  ...,  0.3447,  0.0087,  1.5508],\n",
      "         [ 0.2077, -1.3086, -1.4295,  ..., -0.2998,  0.1828,  0.4700],\n",
      "         [-0.4893,  2.5148, -1.5513,  ...,  0.5783,  1.0961,  0.1736]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "outputs = model(input_ids, attention_mask) # 所以模型的输入是 input_ids 和 attention_mask\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "print(last_hidden_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(outputs['last_hidden_state'].shape)\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualization # 模型是ONNX格式的，不能直接可视化\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# writer = SummaryWriter('./BART')\n",
    "\n",
    "# # add_graph() will trace the sample input through your model,\n",
    "# # and render it as a graph.\n",
    "# # writer.add_graph(model, input_ids, attention_mask)\n",
    "# writer.add_graph(model, inputs['input_ids'], inputs['attention_mask'])\n",
    "\n",
    "# writer.flush()\n",
    "\n",
    "# # To view, start TensorBoard on the command line with:\n",
    "# #   tensorboard --logdir=runs\n",
    "# # ...and open a browser tab to http://localhost:6006/\n",
    "# # 注意上面的'runs'是日志保存的路径，在前面的代码中有设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartModel(\n",
       "  (shared): Embedding(50265, 1024, padding_idx=1)\n",
       "  (encoder): BartEncoder(\n",
       "    (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): GELUActivation()\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): BartDecoder(\n",
       "    (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartDecoder(\n",
       "  (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "  (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "  (layers): ModuleList(\n",
       "    (0-11): 12 x BartDecoderLayer(\n",
       "      (self_attn): BartAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (activation_fn): GELUActivation()\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder_attn): BartAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 1024])\n"
     ]
    }
   ],
   "source": [
    "# 只使用embedder进行运算，得到encoder的运算结果 \n",
    "embeddings = model.shared(input_ids) # 所以模型的输入是 input_ids 和 attention_mask\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside BART: Encoder: input_ids= tensor([[    0, 31414,     6,   127,  2335,    16, 11962,     2]],\n",
      "       device='cuda:0')\n",
      "odict_keys(['last_hidden_state'])\n",
      "torch.Size([1, 8, 1024])\n",
      "tensor([[[-0.0089,  0.0095,  0.0101,  ...,  0.0054, -0.0061, -0.0019],\n",
      "         [-0.0242, -0.2558,  0.1059,  ..., -0.1760,  0.1102,  0.0296],\n",
      "         [ 0.0278, -0.2268,  0.0643,  ...,  0.0303,  0.1538, -0.1770],\n",
      "         ...,\n",
      "         [-0.0684, -0.1958, -0.0589,  ..., -0.0166,  0.1663, -0.1595],\n",
      "         [-0.0161, -0.3884, -0.4422,  ..., -0.0780,  0.0474, -0.0166],\n",
      "         [ 0.0912,  0.0469, -0.0327,  ..., -0.0290, -0.0870,  0.2132]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 只使用encoder进行运算，得到encoder的运算结果，注意调用encoder的时候它默认调佣 embedder\n",
    "encoder_outputs = model.encoder(input_ids, attention_mask) # 所以模型的输入是 input_ids 和 attention_mask\n",
    "representations = encoder_outputs.last_hidden_state\n",
    "print(encoder_outputs.keys())\n",
    "print(representations.shape)\n",
    "print(representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside BART: input_ids= tensor([[    0, 31414,     6,   127,  2335,    16, 11962,     2]],\n",
      "       device='cuda:0')\n",
      "Inside BART: attention_mask= tensor([[1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Inside BART: encoder_hidden_states= None\n",
      "Inside BART: encoder_attention_mask= None\n",
      "Inside BART: head_mask= None\n",
      "Inside BART: cross_attn_head_mask= None\n",
      "Inside BART: past_key_values= None\n",
      "Inside BART: inputs_embeds= None\n",
      "Inside BART: use_cache= None\n",
      "Inside BART: output_attentions= None\n",
      "Inside BART: output_hidden_states= None\n",
      "Inside BART: return_dict= None\n",
      "odict_keys(['last_hidden_state', 'past_key_values'])\n",
      "torch.Size([1, 8, 1024])\n",
      "<class 'tuple'> 12\n",
      "<class 'tuple'> 2\n",
      "<class 'torch.Tensor'> 4\n",
      "tensor([[[-0.7063,  1.2007,  0.1487,  ...,  0.4761, -0.7794, -1.1263],\n",
      "         [-0.7752,  1.0035,  0.8857,  ...,  1.0058,  0.2381, -1.0515],\n",
      "         [-0.2852, -1.1637,  1.8671,  ..., -0.6132,  0.3621, -1.3947],\n",
      "         ...,\n",
      "         [-1.4383,  0.5772,  2.3473,  ...,  0.7001,  0.2143,  1.4135],\n",
      "         [-0.4589, -0.1476,  2.2830,  ...,  0.1734, -0.4468,  0.6591],\n",
      "         [-0.5654,  0.1650,  2.2447,  ...,  0.9836,  0.2274,  0.6033]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 只使用decoder进行运算，得到decoder的运算结果，注意调用decoder的时候它默认调佣 embedder\n",
    "intermediate_output = model.decoder(input_ids, attention_mask) # 所以模型的输入是 input_ids 和 attention_mask\n",
    "predictions = intermediate_output.last_hidden_state\n",
    "print(intermediate_output.keys())\n",
    "print(predictions.shape)\n",
    "print(type(intermediate_output['past_key_values']), len(intermediate_output['past_key_values'])) # 这个应该是指这次保存的 key 和 value值，可以用来做 window attention\n",
    "print(type(intermediate_output['past_key_values'][0]), len(intermediate_output['past_key_values'][0]))\n",
    "print(type(intermediate_output['past_key_values'][0][0]), len(intermediate_output['past_key_values'][0][0].shape))\n",
    "print(predictions) # 这里输出的结果和运行完整模型的结果不一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在的问题是，怎么将 encoder 的输出 单独输入给 decoder？\n",
    "# 是否可以直接给模型的参数赋值？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.container.ModuleList'> 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BartDecoderLayer(\n",
       "  (self_attn): BartAttention(\n",
       "    (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (activation_fn): GELUActivation()\n",
       "  (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (encoder_attn): BartAttention(\n",
       "    (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "  (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# representations torch.Size([1, 8, 1024])\n",
    "print(type(model.decoder.layers), len(model.decoder.layers)) # <class 'torch.nn.modules.container.ModuleList'>  12\n",
    "model.decoder.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside BART: input_ids= tensor([[    2,     0, 31414,     6,   127,  2335,    16, 11962]],\n",
      "       device='cuda:0')\n",
      "Inside BART: attention_mask= None\n",
      "Inside BART: encoder_hidden_states= tensor([[[-0.0089,  0.0095,  0.0101,  ...,  0.0054, -0.0061, -0.0019],\n",
      "         [-0.0242, -0.2558,  0.1059,  ..., -0.1760,  0.1102,  0.0296],\n",
      "         [ 0.0278, -0.2268,  0.0643,  ...,  0.0303,  0.1538, -0.1770],\n",
      "         ...,\n",
      "         [-0.0684, -0.1958, -0.0589,  ..., -0.0166,  0.1663, -0.1595],\n",
      "         [-0.0161, -0.3884, -0.4422,  ..., -0.0780,  0.0474, -0.0166],\n",
      "         [ 0.0912,  0.0469, -0.0327,  ..., -0.0290, -0.0870,  0.2132]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "Inside BART: encoder_attention_mask= tensor([[1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Inside BART: head_mask= None\n",
      "Inside BART: cross_attn_head_mask= None\n",
      "Inside BART: past_key_values= None\n",
      "Inside BART: inputs_embeds= None\n",
      "Inside BART: use_cache= True\n",
      "Inside BART: output_attentions= None\n",
      "Inside BART: output_hidden_states= None\n",
      "Inside BART: return_dict= True\n",
      "odict_keys(['last_hidden_state', 'past_key_values'])\n",
      "torch.Size([1, 8, 1024])\n",
      "<class 'tuple'> 12\n",
      "<class 'tuple'> 4\n",
      "<class 'torch.Tensor'> 4\n",
      "tensor([[[ 0.5512,  0.8389, -1.4707,  ...,  1.3124, -0.2047,  0.2392],\n",
      "         [ 0.5512,  0.8389, -1.4707,  ...,  1.3124, -0.2047,  0.2392],\n",
      "         [ 0.9143,  0.9399, -1.2426,  ...,  0.9184, -0.1838, -0.9975],\n",
      "         ...,\n",
      "         [ 0.2561,  0.2253,  0.4470,  ...,  0.3447,  0.0087,  1.5508],\n",
      "         [ 0.2077, -1.3086, -1.4295,  ..., -0.2998,  0.1828,  0.4700],\n",
      "         [-0.4893,  2.5148, -1.5513,  ...,  0.5783,  1.0961,  0.1736]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nOK，通过打印在两种使用情况下 Decoder接收到的输入，发现，一个关键点，那就是 在EncoderDecoder架构中，\\nDecoder接收到的input_ids是被shuffle过的。为什么？\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只使用decoder进行运算，得到decoder的运算结果，注意调用decoder的时候它默认调佣 embedder\n",
    "temp_ids = torch.tensor([[    2,     0, 31414,     6,   127,  2335,    16, 11962]]).to(device)\n",
    "intermediate_output = model.decoder(temp_ids, \n",
    "                                    encoder_hidden_states=encoder_outputs[0], \n",
    "                                    encoder_attention_mask=attention_mask,\n",
    "                                    use_cache=True,\n",
    "                                    return_dict=True) # 所以模型的输入是 input_ids 和 attention_mask\n",
    "predictions = intermediate_output.last_hidden_state\n",
    "print(intermediate_output.keys())\n",
    "print(predictions.shape)\n",
    "print(type(intermediate_output['past_key_values']), len(intermediate_output['past_key_values'])) # 这个应该是指这次保存的 key 和 value值，可以用来做 window attention\n",
    "print(type(intermediate_output['past_key_values'][0]), len(intermediate_output['past_key_values'][0]))\n",
    "print(type(intermediate_output['past_key_values'][0][0]), len(intermediate_output['past_key_values'][0][0].shape))\n",
    "print(predictions) # 这里输出的结果和运行完整模型的结果不一致\n",
    "\n",
    "'''\n",
    "OK，通过打印在两种使用情况下 Decoder接收到的输入，发现，一个关键点，那就是 在EncoderDecoder架构中，\n",
    "Decoder接收到的input_ids是被shuffle过的。为什么？发生在什么时候？\n",
    "破案了，当直接使用EncoderDecoder的时候，如果没有传入 decoder_input_ids， 那么就会通过对 input_ids 调用 shift_tokens_right 函数\n",
    "得到decoder_input_ids。该函数实现向右移动一个token的功能。\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(encoder_outputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 1045, 1005, 102]], 'attention_mask': [[1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

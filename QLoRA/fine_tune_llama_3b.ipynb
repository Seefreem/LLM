{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:     \n",
    "https://www.databricks.com/blog/efficient-fine-tuning-lora-guide-llms  \n",
    "https://colab.research.google.com/drive/1Vvju5kOyBsDr7RX_YAvp6ZsSOoSMjhKD?usp=sharing#scrollTo=L2Hllu-bCuN6  \n",
    "https://www.youtube.com/watch?v=NRVaRXDoI3g  \n",
    "https://blog.csdn.net/LF_AI/article/details/132419546  \n",
    "\n",
    "Software environment：  \n",
    "requirements.txt  \n",
    "Cuda compilation tools, release 10.1, V10.1.243   \n",
    "NVIDIA-SMI 545.23.08  Driver Version: 545.23.08    CUDA Version: 12.3  \n",
    "Nvidia GTX 3060"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main steps\n",
    "1. Loading dataset\n",
    "2. Data pre-processing\n",
    "3. Creating prompt template\n",
    "4. Instanciating LoraConfig object\n",
    "5. Loading LoRA model and tokenizer\n",
    "6. Testing before fine-tuning\n",
    "7. Setting up a Trainer\n",
    "8. Fine-tuning\n",
    "9. Testing after fine-tuning\n",
    "9. Saving fine-tuned model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seelur/anaconda3/envs/pytorch2.0/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/seelur/anaconda3/envs/pytorch2.0/lib/python3.11/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "/home/seelur/anaconda3/envs/pytorch2.0/lib/python3.11/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from trl import SFTTrainer\n",
    "import torch\n",
    "import mlflow\n",
    "from transformers import BitsAndBytesConfig, DataCollatorForSeq2Seq\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType, PeftModelForCausalLM\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, Trainer\n",
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, logging, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biamp Rack Products</td>\n",
       "      <td>Digital Audio Processors</td>\n",
       "      <td>“High recognition value, uniform aesthetics an...</td>\n",
       "      <td>Product Name: Biamp Rack Products;\\n\\nProduct ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V33</td>\n",
       "      <td>Video Camera</td>\n",
       "      <td>The V33 livestreaming video camera ensures hig...</td>\n",
       "      <td>Product Name: V33;\\n\\nProduct Category: Video ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP LaserJet 5000-6000 and E700-E800 Series MFPs</td>\n",
       "      <td>Multi-Function Printers</td>\n",
       "      <td>The HP LaserJet 5000 to 6000 Series and E700 t...</td>\n",
       "      <td>Product Name: HP LaserJet 5000-6000 and E700-E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meaco Arete One 20L Dehumidifier</td>\n",
       "      <td>Heating and Air Conditioning Technology</td>\n",
       "      <td>The Meaco Arete One Dehumidifier is characteri...</td>\n",
       "      <td>Product Name: Meaco Arete One 20L Dehumidifier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>théATRE Glass Container for Loose Leaf Tea</td>\n",
       "      <td>Food Containers</td>\n",
       "      <td>The design and colouring of the théATRE Glass ...</td>\n",
       "      <td>Product Name: théATRE Glass Container for Loos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           product  \\\n",
       "0                              Biamp Rack Products   \n",
       "1                                              V33   \n",
       "2  HP LaserJet 5000-6000 and E700-E800 Series MFPs   \n",
       "3                 Meaco Arete One 20L Dehumidifier   \n",
       "4       théATRE Glass Container for Loose Leaf Tea   \n",
       "\n",
       "                                  category  \\\n",
       "0                 Digital Audio Processors   \n",
       "1                             Video Camera   \n",
       "2                  Multi-Function Printers   \n",
       "3  Heating and Air Conditioning Technology   \n",
       "4                          Food Containers   \n",
       "\n",
       "                                         description  \\\n",
       "0  “High recognition value, uniform aesthetics an...   \n",
       "1  The V33 livestreaming video camera ensures hig...   \n",
       "2  The HP LaserJet 5000 to 6000 Series and E700 t...   \n",
       "3  The Meaco Arete One Dehumidifier is characteri...   \n",
       "4  The design and colouring of the théATRE Glass ...   \n",
       "\n",
       "                                                text  \n",
       "0  Product Name: Biamp Rack Products;\\n\\nProduct ...  \n",
       "1  Product Name: V33;\\n\\nProduct Category: Video ...  \n",
       "2  Product Name: HP LaserJet 5000-6000 and E700-E...  \n",
       "3  Product Name: Meaco Arete One 20L Dehumidifier...  \n",
       "4  Product Name: théATRE Glass Container for Loos...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset from the HuggingFace Hub\n",
    "rd_ds = load_dataset(\"xiyuez/red-dot-design-award-product-description\")\n",
    "#Convert to pandas dataframe for convenient processing\n",
    "# 将数据转化为pandas的dataframe，方便处理 \n",
    "rd_df = pd.DataFrame(rd_ds['train'])\n",
    "rd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>instruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biamp Rack Products</td>\n",
       "      <td>Digital Audio Processors</td>\n",
       "      <td>“High recognition value, uniform aesthetics an...</td>\n",
       "      <td>Product Name: Biamp Rack Products;\\n\\nProduct ...</td>\n",
       "      <td>Create a detailed description for the followin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V33</td>\n",
       "      <td>Video Camera</td>\n",
       "      <td>The V33 livestreaming video camera ensures hig...</td>\n",
       "      <td>Product Name: V33;\\n\\nProduct Category: Video ...</td>\n",
       "      <td>Create a detailed description for the followin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP LaserJet 5000-6000 and E700-E800 Series MFPs</td>\n",
       "      <td>Multi-Function Printers</td>\n",
       "      <td>The HP LaserJet 5000 to 6000 Series and E700 t...</td>\n",
       "      <td>Product Name: HP LaserJet 5000-6000 and E700-E...</td>\n",
       "      <td>Create a detailed description for the followin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meaco Arete One 20L Dehumidifier</td>\n",
       "      <td>Heating and Air Conditioning Technology</td>\n",
       "      <td>The Meaco Arete One Dehumidifier is characteri...</td>\n",
       "      <td>Product Name: Meaco Arete One 20L Dehumidifier...</td>\n",
       "      <td>Create a detailed description for the followin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>théATRE Glass Container for Loose Leaf Tea</td>\n",
       "      <td>Food Containers</td>\n",
       "      <td>The design and colouring of the théATRE Glass ...</td>\n",
       "      <td>Product Name: théATRE Glass Container for Loos...</td>\n",
       "      <td>Create a detailed description for the followin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           product  \\\n",
       "0                              Biamp Rack Products   \n",
       "1                                              V33   \n",
       "2  HP LaserJet 5000-6000 and E700-E800 Series MFPs   \n",
       "3                 Meaco Arete One 20L Dehumidifier   \n",
       "4       théATRE Glass Container for Loose Leaf Tea   \n",
       "\n",
       "                                  category  \\\n",
       "0                 Digital Audio Processors   \n",
       "1                             Video Camera   \n",
       "2                  Multi-Function Printers   \n",
       "3  Heating and Air Conditioning Technology   \n",
       "4                          Food Containers   \n",
       "\n",
       "                                         description  \\\n",
       "0  “High recognition value, uniform aesthetics an...   \n",
       "1  The V33 livestreaming video camera ensures hig...   \n",
       "2  The HP LaserJet 5000 to 6000 Series and E700 t...   \n",
       "3  The Meaco Arete One Dehumidifier is characteri...   \n",
       "4  The design and colouring of the théATRE Glass ...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Product Name: Biamp Rack Products;\\n\\nProduct ...   \n",
       "1  Product Name: V33;\\n\\nProduct Category: Video ...   \n",
       "2  Product Name: HP LaserJet 5000-6000 and E700-E...   \n",
       "3  Product Name: Meaco Arete One 20L Dehumidifier...   \n",
       "4  Product Name: théATRE Glass Container for Loos...   \n",
       "\n",
       "                                         instruction  \n",
       "0  Create a detailed description for the followin...  \n",
       "1  Create a detailed description for the followin...  \n",
       "2  Create a detailed description for the followin...  \n",
       "3  Create a detailed description for the followin...  \n",
       "4  Create a detailed description for the followin...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine the two attributes into an instruction string\n",
    "# 通过pandas的操作，批量构建 instruction prompt \n",
    "rd_df['instruction'] = 'Create a detailed description for the following product: '+ rd_df['product']+', belonging to category: '+ rd_df['category']\n",
    "rd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Create a detailed description for the following product: Biamp Rack Products, belonging to category: Digital Audio Processors'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_df['instruction'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Create a detailed description for the followin...</td>\n",
       "      <td>“High recognition value, uniform aesthetics an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Create a detailed description for the followin...</td>\n",
       "      <td>The V33 livestreaming video camera ensures hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Create a detailed description for the followin...</td>\n",
       "      <td>The HP LaserJet 5000 to 6000 Series and E700 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Create a detailed description for the followin...</td>\n",
       "      <td>The Meaco Arete One Dehumidifier is characteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Create a detailed description for the followin...</td>\n",
       "      <td>The design and colouring of the théATRE Glass ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  Create a detailed description for the followin...   \n",
       "1  Create a detailed description for the followin...   \n",
       "2  Create a detailed description for the followin...   \n",
       "3  Create a detailed description for the followin...   \n",
       "4  Create a detailed description for the followin...   \n",
       "\n",
       "                                         description  \n",
       "0  “High recognition value, uniform aesthetics an...  \n",
       "1  The V33 livestreaming video camera ensures hig...  \n",
       "2  The HP LaserJet 5000 to 6000 Series and E700 t...  \n",
       "3  The Meaco Arete One Dehumidifier is characteri...  \n",
       "4  The design and colouring of the théATRE Glass ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_df = rd_df[['instruction', 'description']]\n",
    "rd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a 5000 sample subset for fine-tuning purposes\n",
    "# 取前面5000个样本先测试整个流程\n",
    "rd_df_sample = rd_df.sample(n=5000, random_state=42)\n",
    "#Define template and format data into the template for supervised fine-tuning\n",
    "template = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "\n",
    "{}\n",
    "\n",
    "### Response:\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“High recognition value, uniform aesthetics and practical scalability – this has been impressively achieved with the Biamp brand language,” the jury statement said. The previous design of the digital audio processors was not only costly to produce, but also incompatible with newer system architectures. With the new concept, the company is making a visual statement that allows for differences in dimension, connectivity and application. Design elements include consistent branding, a soft curve on the top and bottom edges, and two red bars on the left and right margins of the products. The two-part black front panel can be used for various products.\n",
      "### End\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18952</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>The CG8565 is a gaming PC offering space for h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12584</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>The iSHOXS BullBar ProX mount can be used to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>The S81 Pro focuses on two things: outstanding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20503</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>The CenFlex superfinish machine is designed fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>The THALION S gas absorption heat pump uses na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  prompt  \\\n",
       "18952  Below is an instruction that describes a task....   \n",
       "12584  Below is an instruction that describes a task....   \n",
       "5702   Below is an instruction that describes a task....   \n",
       "20503  Below is an instruction that describes a task....   \n",
       "2480   Below is an instruction that describes a task....   \n",
       "\n",
       "                                                response  \n",
       "18952  The CG8565 is a gaming PC offering space for h...  \n",
       "12584  The iSHOXS BullBar ProX mount can be used to a...  \n",
       "5702   The S81 Pro focuses on two things: outstanding...  \n",
       "20503  The CenFlex superfinish machine is designed fo...  \n",
       "2480   The THALION S gas absorption heat pump uses na...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rd_df_sample['prompt'] = rd_df_sample[\"instruction\"].apply(lambda x: template.format(x))\n",
    "# Rename columns. 重命名列\n",
    "rd_df_sample.rename(columns={'description': 'response'}, inplace=True)\n",
    "rd_df_sample['response'] = rd_df_sample['response'] + \"\\n### End\"\n",
    "rd_df_sample = rd_df_sample[['prompt', 'response']]\n",
    "print(rd_df_sample['response'][0])\n",
    "rd_df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18952</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12584</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20503</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "18952  Below is an instruction that describes a task....\n",
       "12584  Below is an instruction that describes a task....\n",
       "5702   Below is an instruction that describes a task....\n",
       "20503  Below is an instruction that describes a task....\n",
       "2480   Below is an instruction that describes a task...."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_df_sample['text'] = rd_df_sample[\"prompt\"] + rd_df_sample[\"response\"]\n",
    "# Drop columns. 删除列\n",
    "rd_df_sample.drop(columns=['prompt', 'response'], inplace=True)\n",
    "rd_df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "###Instruction:  \n",
    "Create a detailed description for the following product: Corelogic Smooth Mouse, belonging to category: Optical Mouse\n",
    "\n",
    "###Response:  \n",
    "Corelogic Smooth Mouse is a mouse that is designed to be used by people who have a hard time using a mouse. The mouse is designed to be used by people who have a hard time using a mouse. The mouse is designed to be used by people who have a hard time using a mouse. The mouse is designed to be used by people who have a hard time using a mouse. The mouse is designed to be used by people who have a hard time using a mouse. The mouse is designed to be used by people who have a hard time using a mouse. The mouse is designed to be used by people who have a hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Turnable Knobs\n",
    "Two of these hyperparameters, r and target_modules are empirically shown to affect adaptation quality significantly and will be the focus of the tests that follow. The other hyperparameters are kept constant at the values indicated above for simplicity.\n",
    "\n",
    "Thus, it is a common practice to only target the attention blocks of the transformer. However, recent work as shown in the QLoRA paper by Dettmers et al. suggests that targeting all linear layers results in better adaptation quality. This will be explored here as well.\n",
    "https://arxiv.org/abs/2305.14314 《QLoRA: Efficient Finetuning of Quantized LLMs》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "#If only targeting attention blocks of the model\n",
    "# 设置需要LoRA微调的模块。可以通过打印模型查看模型具体的模块名。\n",
    "target_modules = [\"q_proj\", \"v_proj\"]\n",
    "\n",
    "#If targeting all linear layers\n",
    "# target_modules = ['q_proj','k_proj','v_proj','o_proj','gate_proj','down_proj','up_proj','lm_head']\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    target_modules = target_modules,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    # full_determinism=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the finetuning with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Quantification config \n",
    "# 量化配置文件 \n",
    "nf4_config = BitsAndBytesConfig(\n",
    "  load_in_4bit=True,\n",
    "  bnb_4bit_quant_type=\"nf4\",\n",
    "  bnb_4bit_use_double_quant=True,\n",
    "  bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "# load a quantified model\n",
    "# 加载量化后的模型\n",
    "model_path = 'openlm-research/open_llama_3b_v2'\n",
    "row_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path, device_map='auto', quantization_config=nf4_config,\n",
    ") \n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_path, device_map='auto',\n",
    "# )\n",
    "\n",
    "# With or without LoRA parameters, the results are almost the same. Because it is not fine-tuned right now.\n",
    "# This function only add LoRA plugin, instead of loading fine-tuned LoRA parameters\n",
    "# 加载配置了LoRA的模型\n",
    "model = get_peft_model(row_model, lora_config)\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seelur/anaconda3/envs/pytorch2.0/lib/python3.11/site-packages/transformers/generation/utils.py:1535: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Q: Create a detailed description for the following product: Corelogic Smooth Mouse, belonging to category: Optical Mouse\n",
      "A: Corelogic Smooth Mouse is a mouse that is designed to be used with a computer. It is a wireless mouse that has a 2.4 GHz wireless connection. It has a 2.4 GHz wireless connection and a 2.4 GHz wireless connection. It has a 2.4 GHz wireless connection and a 2.4 GHz wireless connection. It has a 2.4 GHz wireless connection and a 2.4 GHz wireless connection. It has a 2.4 GHz wireless connection and a 2.4 GHz wireless connection. It has a 2.4 GHz wireless connection and a 2.4 GHz wireless connection. It has a 2.4 GHz wireless connection and a 2.4 GHz wireless connection. It has a 2.4 GHz wireless connection and a 2.4 GHz wireless connection. It has a 2.4 GHz wireless connection and a 2.4 GHz wireless connection. It has a 2.4 GHz wireless connection and a 2.4 GHz wireless connection. It has a 2.4 GHz wireless connection and a 2.4 G\n"
     ]
    }
   ],
   "source": [
    "#Pass in a prompt and infer with the model\n",
    "prompt = 'Q: Create a detailed description for the following product: Corelogic Smooth Mouse, belonging to category: Optical Mouse\\nA:'\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "generation_output = model.generate(\n",
    "input_ids=input_ids, max_new_tokens=250\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(generation_output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Create a detailed description for the following product: Corelogic Smooth Mouse, belonging to category: Optical Mouse\n",
    "\n",
    "A: The product is a mouse that has a smooth surface. It is a mouse that is used for computer use. It is a mouse that is used for computer use. It is a mouse that is used for computer use. It is a mouse that is used for computer use. It is a mouse that is used for computer use. It is a mouse that is used for computer use. It is a mouse that is used for computer use. It is a mouse that is used for computer use. It is a mouse that is used for computer use. It is a mouse that is used for computer use. It is a mouse that is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"./\"\n",
    "per_device_train_batch_size = 4\n",
    "gradient_accumulation_steps = 4\n",
    "optim = 'adamw_hf'\n",
    "learning_rate = 1e-5\n",
    "max_grad_norm = 0.3\n",
    "warmup_ratio = 0.03\n",
    "lr_scheduler_type = \"linear\"\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=base_dir,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs = 3.0,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    learning_rate=learning_rate,\n",
    "    fp16=True,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Map: 100%|██████████| 4750/4750 [00:00<00:00, 14222.46 examples/s]\n",
      "Map: 100%|██████████| 250/250 [00:00<00:00, 14290.25 examples/s]\n",
      "/home/seelur/anaconda3/envs/pytorch2.0/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:247: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "/home/seelur/anaconda3/envs/pytorch2.0/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/891 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "                                                 \n",
      " 33%|███▎      | 297/891 [16:09<26:25,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0675911903381348, 'eval_runtime': 25.9704, 'eval_samples_per_second': 9.626, 'eval_steps_per_second': 1.232, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 500/891 [27:02<25:12,  3.87s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2971, 'learning_rate': 4.525462962962963e-06, 'epoch': 1.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 67%|██████▋   | 594/891 [32:26<13:44,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.949227213859558, 'eval_runtime': 26.0417, 'eval_samples_per_second': 9.6, 'eval_steps_per_second': 1.229, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "100%|██████████| 891/891 [48:46<00:00,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9263529777526855, 'eval_runtime': 25.9703, 'eval_samples_per_second': 9.626, 'eval_steps_per_second': 1.232, 'epoch': 3.0}\n",
      "{'train_runtime': 2926.5679, 'train_samples_per_second': 4.869, 'train_steps_per_second': 0.304, 'train_loss': 2.1083144542210297, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(rd_df_sample).train_test_split(test_size=0.05, seed=42)\n",
    "trainer = SFTTrainer( # Supervised Finetuning Trainer\n",
    "    # trainer = Trainer( \n",
    "    model,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset =dataset['test'],\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=256,\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "# Initiate the training process\n",
    "with mlflow.start_run(run_name = 'test'):\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seelur/anaconda3/envs/pytorch2.0/lib/python3.11/site-packages/transformers/generation/utils.py:1535: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Q: Create a detailed description for the following product: Corelogic Smooth Mouse, belonging to category: Optical Mouse\n",
      "A: The Corelogic Smooth Mouse is a high-end optical mouse with a 1000 DPI sensor. The mouse is equipped with a 3-button mouse wheel and a scroll wheel. The mouse is available in black and white.\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Pass in a prompt and infer with the model\n",
    "prompt = 'Q: Create a detailed description for the following product: Corelogic Smooth Mouse, belonging to category: Optical Mouse\\nA:'\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "generation_output = model.generate(\n",
    "input_ids=input_ids, max_new_tokens=250\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(generation_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ValueError: Cannot merge LORA layers when the model is loaded in 8-bit mode. \n",
    "# merge_and_unload() is not supported in this version.\n",
    "# merged_model = model.merge_and_unload() \n",
    "model.save_pretrained(\"adapter_model\") # Saving adaptor (fine-tuned LoRA parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved model and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Q: Create a detailed description for the following product: Corelogic Smooth Mouse, belonging to category: Optical Mouse\n",
      "A: The Corelogic Smooth Mouse is a high-quality optical mouse with a smooth surface. The mouse is equipped with a 1000 dpi sensor and a 1000 Hz polling rate. The mouse is compatible with Windows 7, 8 and 10.\n",
      "Q: Create a detailed description for the following product: Corelogic Smooth Mouse, belonging to category: Optical Mouse\n",
      "A: The Corelogic Smooth Mouse is a high-quality optical mouse with a smooth surface. The mouse is equipped with a 1000 dpi sensor and a 1000 Hz polling rate. The mouse is compatible with Windows 7, 8 and 10.\n",
      "Q: Create a detailed description for the following product: Corelogic Smooth Mouse, belonging to category: Optical Mouse\n",
      "A: The Corelogic Smooth Mouse is a high-quality optical mouse with a smooth surface. The mouse is equipped with a 1000 dpi sensor and a 1000 Hz polling rate. The mouse is compatible with Windows 7, 8 and 10.\n",
      "Q: Create a detailed description for the following product: Corelogic Smooth Mouse\n"
     ]
    }
   ],
   "source": [
    "## load pretrained model and LoRA adaptor\n",
    "# lora_path = 'fine-tuned-llama-3B-LoRA'\n",
    "lora_path = './adapter_model'\n",
    "model_path = 'openlm-research/open_llama_3b_v2'\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    model_path, load_in_8bit=True, device_map='auto',\n",
    ")\n",
    "\n",
    "model = PeftModelForCausalLM.from_pretrained(model, lora_path)\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path)\n",
    "\n",
    "prompt = 'Q: Create a detailed description for the following product: Corelogic Smooth Mouse, belonging to category: Optical Mouse\\nA:'\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "# generation_output = peft_model.generate(input_ids=input_ids, max_new_tokens=250)\n",
    "generation_output = model.generate(input_ids=input_ids.cuda(), max_new_tokens=250)\n",
    "print(tokenizer.decode(generation_output[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
